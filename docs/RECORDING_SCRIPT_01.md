# 📹 第1回録画台本：Cursor AIで学ぶDify + pgvector RAG構築

**タイトル**: 「Cursor AIプログラミングで5分RAG構築！Dify + pgvectorでAIチャットを作る」  
**所要時間**: 20分  
**録画日**: 2025年10月18日

---

## 📋 事前準備チェックリスト

### 環境準備
```bash
# ターミナルで実行
cd ~/
docker compose down -v  # 既存環境をクリーン
clear
history -c  # コマンド履歴をクリア
```

### Cursor設定
- [ ] AI Chatパネル: 右側に表示（Cmd/Ctrl + L で開く）
- [ ] フォントサイズ: 16pt以上
- [ ] テーマ: One Dark Pro（見やすい配色）
- [ ] ファイルツリー: 表示

### ブラウザ設定
- [ ] Chrome シークレートウィンドウ
- [ ] ブックマークバー: 非表示
- [ ] ズーム: 125%
- [ ] 開発者ツール: 閉じる

### 画面配置
```
┌─────────────────────────────────────────────┐
│  左: Cursor (60%)    │  右: ブラウザ/ターミナル (40%) │
└─────────────────────────────────────────────┘
```

### 録画設定
- [ ] OBS / Screen Recording 起動
- [ ] マイク音声レベル確認
- [ ] 解像度: 1920x1080
- [ ] テスト録画（5秒）実施

---

## 🎬 本編台本

### 【00:00-01:30】オープニング＋プロジェクト紹介

#### 画面: Cursorのウェルカム画面

**セリフ:**
```
こんにちは！今日は『Cursor AIプログラミングで学ぶ
DifyとpgvectorによるRAGシステム構築』をお届けします。

私は普段、AIインフラを教えている講師なんですが、
最近話題のCursorを使って、どこまでAIに頼りながら
開発できるのか、リアルタイムで見せていきます。

[画面操作: Cursorのロゴを表示]

Cursorって使ったことありますか？
VSCodeベースのエディタなんですが、AIと対話しながら
コードを書けるのが特徴です。

今日作るのは、RAGシステム。
Retrieval-Augmented Generationの略で、
要は『社内ドキュメントを理解して回答できるAIチャット』です。

では早速、始めていきましょう！
```

**カメラワーク:** 笑顔で手を振る、明るいトーン

---

### 【01:30-04:00】プロジェクトのクローンと構造理解

#### 画面: ターミナル（全画面）

**セリフ:**
```
まず、プロジェクトをクローンします。
GitHubに公開されているので、誰でも使えます。
```

**操作（ゆっくりタイプ）:**
```bash
git clone https://github.com/togashira/dify_vectordb_autoprograming.git

# [Enter] を押す、完了を待つ（5秒）

cd dify_vectordb_autoprograming

# ファイル一覧を表示
ls -la
```

**セリフ:**
```
クローンできました。
docker-compose.yml、README.md、samplesフォルダ...
必要なファイルが揃ってますね。

じゃあ、このプロジェクトの構造を、Cursorに聞いてみましょう。
```

**注意:** 各コマンド実行後、結果が表示されるまで3秒待つ

---

#### 画面: Cursorでプロジェクトを開く

**操作:**
```
[File] > [Open Folder] > dify_vectordb_autoprograming を選択
```

**セリフ:**
```
プロジェクトが開きました。
左側にファイル一覧が見えますね。

README.mdが気になるので開いてみます。
```

**操作:**
```
ファイルツリーから README.md をクリック
```

---

#### 画面: README.md（セクション4を表示）

**セリフ:**
```
おー、結構詳しく書いてありますね。
684行もある！

[スクロールして]

あ、『4. ベクトルDB戦略の選択』っていうセクションがあります。
選択肢AとBがあるみたいですが...

[セクション4をゆっくり読む雰囲気]

正直、初見だとこれだけじゃ分かりづらいですよね。
こういう時こそ、Cursorの出番です！
```

**カメラワーク:** README.mdの該当箇所をマウスでハイライト

---

### 【04:00-07:00】Cursor AIに質問（戦略の選択）

#### 画面: Cursor AI Chatパネルを開く

**操作:**
```
Cmd/Ctrl + L を押す（AIチャットが右側に開く）
```

**セリフ:**
```
CursorのAIチャット機能を使います。
ショートカットはCmd+Lです。

ここに質問を入力すると、AIが答えてくれます。
しかも、@マークでファイルを指定できるので、
そのファイルの内容を理解した上で答えてくれるんです。

では質問してみます。
```

---

**AIへの質問（ゆっくりタイプ、視聴者が読める速度）:**
```
@README.md セクション4の「ベクトルDB戦略の選択」について、
選択肢Aと選択肢Bの違いを、初心者にも分かるように説明してください。
それぞれどんな人に向いているかも教えてください。
```

**操作:** [Enter] を押す

**セリフ（AIの回答を待ちながら）:**
```
@README.mdと指定することで、このファイルの内容を
読み込んだ状態で答えてくれます。

[3秒待つ]

おっ、回答が来ました。読んでみましょう。
```

**注意:** AIの回答が表示されたら、ゆっくりスクロールしながら読む

---

**セリフ（AIの回答を読みながら）:**
```
なるほど...

[回答の重要部分を読み上げる]

選択肢Aは、Difyの初期設定のまま使うパターン。
これは10万件くらいまでのデータで、
学習や小規模アプリに向いてるって。

選択肢Bは、pgvectorを独自にチューニングするパターン。
こっちは10万件以上の大規模データや、
本番環境で高速化が必要な場合って書いてありますね。

[カメラ目線で]
今回は学習目的なので、選択肢Aで行きます！

では次に、起動方法を聞いてみましょう。
```

**カメラワーク:** AIの回答をマウスでなぞりながら説明

---

### 【07:00-10:00】起動手順をAIに聞く

**AIへの質問:**
```
@README.md このプロジェクトを起動する手順を、
コマンドも含めて教えてください。
初めて使う人向けに、ステップバイステップでお願いします。
```

**操作:** [Enter] を押す、回答を待つ

---

**セリフ（AIの回答を読みながら）:**
```
AIが手順を教えてくれました。

[回答を読み上げる]

1. docker compose up -d で起動
2. docker compose exec dify-api flask db upgrade でマイグレーション
3. http://localhost:8080/install にアクセス

シンプルですね。では実際にやってみます。
```

---

#### 画面: ターミナルに切り替え

**操作:**
```bash
# ターミナルを右側40%に配置
docker compose up -d
```

**セリフ（コマンド実行中）:**
```
Docker Composeでコンテナを起動しています。

[ログが流れる様子を見せる]

初回は画像のダウンロードがあるので、
5-10分くらいかかります。

[画面に字幕: "5分後..." を表示、または早送り]

起動しました！
コンテナが全部 "Started" になってますね。

では次にデータベースのマイグレーションです。
```

---

**操作:**
```bash
# 2. マイグレーション
docker compose exec dify-api flask db upgrade
```

**セリフ（実行中）:**
```
マイグレーションが実行されています。
これは、データベースのテーブルを作成する処理です。

[ログを見る]

"INFO [alembic.runtime.migration] Running upgrade"
って出てますね。

[待つ 10秒]

...完了しました！
"INFO [alembic.runtime.migration] Will assume transactional DDL."
成功の証拠です。

では、ブラウザでアクセスしてみます。
```

**注意:** マイグレーションログが表示される様子をしっかり見せる

---

### 【10:00-13:00】Difyの初期セットアップ

#### 画面: ブラウザ（Cursor横40%に配置）

**操作:**
```
ブラウザのアドレスバーに入力:
http://localhost:8080/install
```

**セリフ:**
```
ブラウザで localhost:8080/install にアクセスします。

[ページ読み込み中 3秒]

お、セットアップ画面が表示されました。

管理者ユーザーを作成する画面ですね。
入力していきます。
```

---

**操作（画面に入力しながら、ゆっくり）:**
```
Email: demo@example.com
Name: Demo User
Password: demo123456
[パスワードを再入力]

[Continue] ボタンをクリック
```

**セリフ:**
```
セットアップ完了です！

[画面遷移 3秒]

Difyのメイン画面が表示されました。
左側にメニューがありますね。

[マウスでメニューを指しながら]
- Studio: アプリを作る場所
- Knowledge: ドキュメントを管理する場所
- Datasets: データセット管理

今回はDatasetsを使います。

でもその前に、pgvectorの中身を確認してみたいですね。
裏側で何が起きているのか見てみましょう。

Cursorに聞いてみます。
```

**カメラワーク:** Difyの各メニューをゆっくり見せる

---

### 【13:00-16:00】pgvectorのテーブル構造を確認

#### 画面: Cursorに戻る（AIチャット）

**AIへの質問:**
```
このプロジェクトで使っているpgvectorのテーブル構造を
確認するには、どんなコマンドを実行すればいいですか？

psqlでログインするコマンドと、
テーブル一覧を表示するSQLコマンドを教えてください。
```

**操作:** [Enter]、回答を待つ

---

**セリフ（AIの回答を読む）:**
```
なるほど、こういうコマンドを実行すればいいんですね。

[回答を読み上げる]

docker compose exec db psql -U dify -d dify

これでPostgreSQLにログインして、

\dt

でテーブル一覧が見られる。やってみます。
```

---

#### 画面: ターミナル

**操作:**
```bash
docker compose exec db psql -U dify -d dify
```

**セリフ:**
```
PostgreSQLに接続できました。
プロンプトが dify=# に変わりましたね。

ではテーブル一覧を表示します。
```

---

**操作（psql内）:**
```sql
\dt
```

**セリフ（結果を見ながら）:**
```
たくさんテーブルがありますね！

[マウスでテーブル名を指しながら]
- accounts
- datasets
- documents
- document_segments
- embeddings ← これがpgvectorのテーブル！

embeddingsテーブルの構造を見てみましょう。
```

**注意:** テーブル一覧をゆっくりスクロール、視聴者が読める速度

---

**操作:**
```sql
\d+ embeddings
```

**セリフ（結果を見ながら）:**
```
おー、詳細が表示されました。

[カラムを指しながら]
- id: UUID
- model_name: 使用した埋め込みモデル
- hash: ハッシュ値
- embedding: vector型 ← これがベクトルデータ！

vectorって型がPostgreSQLの標準じゃない特殊な型で、
pgvector拡張によって追加されたものです。

実際のデータを1件見てみましょう。
```

---

**操作:**
```sql
SELECT id, model_name, LEFT(embedding::text, 50) AS embedding_preview
FROM embeddings
LIMIT 1;
```

**セリフ:**
```
[結果を見る]

ん？まだデータが入ってないですね。
それもそのはず、まだドキュメントをアップロードしてないので。

では次に、実際にドキュメントをアップロードして、
pgvectorにデータが入る様子を見てみましょう！

psqlを抜けます。
```

**操作:**
```sql
\q
```

---

### 【16:00-19:00】データセット作成とベクトル化の確認

#### 画面: ブラウザ（Dify）

**セリフ:**
```
Difyに戻ります。

左メニューから Datasets を選択して...
```

**操作:**
```
[Knowledge] > [Datasets] をクリック
[Create Dataset] ボタンをクリック
```

**セリフ:**
```
データセット作成画面が開きました。
```

---

**操作:**
```
Dataset Name: ぎゃるでれらプロフィール
Description: ギャル風シンデレラのキャラクター設定

[Create] をクリック
```

**セリフ:**
```
データセットができました。

次にドキュメントをアップロードします。
このプロジェクトのsamplesフォルダに、
サンプルファイルがあるはずです。
```

---

#### 画面: Cursorに切り替え（ファイルツリー表示）

**セリフ:**
```
Cursorのファイルツリーを見ると...

[マウスでフォルダを指す]

samples/gyaru_cinderella_profile.md

ありました！これをアップロードしてみます。
```

**操作:**
```
samples/gyaru_cinderella_profile.md を右クリック
> Reveal in Finder / Show in Explorer
```

---

#### 画面: ブラウザ（Dify）に戻る

**操作:**
```
[Add Document] をクリック
→ [Upload File] を選択
→ ファイルを選択: gyaru_cinderella_profile.md
→ [Upload] をクリック
```

**セリフ:**
```
アップロードされました！

[画面を見る]

今、"Indexing..." って表示されてますね。
プログレスバーが動いています。

これが、テキストをベクトルに変換して
pgvectorに保存している処理です。

この裏側で何が起きているか、Cursorに聞いてみましょう。
```

**注意:** Indexingの進行状況をしっかり見せる（5-10秒）

---

#### 画面: Cursor AIチャット

**AIへの質問:**
```
Difyでドキュメントをアップロードして
"Indexing"が始まったとき、裏側では
どんな処理が行われていますか？

特に、pgvectorとの連携部分について
詳しく教えてください。
```

**操作:** [Enter]、回答を待つ

---

**セリフ（AIの回答を読む）:**
```
なるほど、こういう流れなんですね。

[回答を読み上げる]

1. テキストをチャンク（小さな塊）に分割
2. 各チャンクを埋め込みモデル（Embedding Model）でベクトル化
3. ベクトルをpgvectorのembeddingsテーブルに保存

シンプルですが、これがRAGの基本です。

[ブラウザを見る]

インデックスが完了したようなので、
pgvectorにデータが入ったか確認してみます。
```

---

#### 画面: ターミナル

**操作:**
```bash
docker compose exec db psql -U dify -d dify -c "SELECT COUNT(*) FROM embeddings;"
```

**セリフ:**
```
おー、5件入ってますね！

ドキュメントが5つのチャンクに分割されて、
それぞれがベクトル化されたってことです。

実際のベクトルを見てみましょう。
```

---

**操作:**
```bash
docker compose exec db psql -U dify -d dify -c "SELECT id, model_name, LEFT(embedding::text, 100) AS embedding_preview FROM embeddings LIMIT 1;"
```

**セリフ（結果を見ながら）:**
```
ベクトルデータが表示されました！

[画面を指す]

[0.123, 0.456, 0.789, ...] みたいな
数値の配列になってますね。

これが『ぎゃるでれら』の口調や性格を
数値で表現したものです。

すごいですよね。
「超マジ」とか「やばたにえん」みたいな
ギャル語の特徴が、この数値の並びに
エンコードされているわけです。
```

**カメラワーク:** ベクトルの数値をゆっくり見せる

---

### 【19:00-20:00】まとめと次回予告

#### 画面: Cursorに戻る（README.mdを表示）

**セリフ:**
```
では、今日のまとめです。

Cursorを使って、Dify + pgvectorの環境を構築しました。

やったことは：

[指で数えながら]

1. プロジェクトのクローン
2. Cursorで構造を理解
3. AIに質問しながら起動
4. pgvectorのテーブル確認
5. ドキュメントのベクトル化

全部AIに聞きながら進めたので、
ドキュメントを読む時間が圧倒的に短縮されました。

今日のポイントは、
```

---

**セリフ（続き）:**
```
[Cursorの@機能を指す]

@README.mdのように
ファイルを指定して質問すると、
そのファイルの内容を理解した上で答えてくれる、
ってところですね。

これ、マジで便利です。

次回は、

[画面操作: README.mdのセクション7を表示、スクロール]

このデータアーキテクチャを深掘りして、
RAGの仕組みをもっと詳しく見ていきます。

そして、Cursorを使って
DATA_ARCHITECTURE.mdっていうドキュメントを
AIに生成させてみようと思います。

お楽しみに！

それでは、また次回！

[手を振る]
```

**カメラワーク:** 明るい表情で締める

---

## 🎯 録画時のアドリブポイント

### つまずきシーン（意図的に見せる）

#### シーン1: ポート衝突エラー
```bash
docker compose up -d
# → Error: port 8080 already allocated

【セリフ】
「あ、エラーが出ました。
ポート8080が既に使われてるみたいです。

こういう時もCursorに聞けば解決できます。」

【AIに質問】
@docker-compose.yml ポート8080が既に使用されていると
エラーが出ました。どうすれば解決できますか？

【解決】
# → .envファイルでHOST_PORT=8081に変更
```

---

#### シーン2: マイグレーション忘れ
```
【現象】
ブラウザでアクセス → ローディング画面で止まる

【セリフ】
「あれ、画面が表示されませんね。
ログを確認してみます。」

docker compose logs dify-api --tail=20

「あ、"table does not exist"ってエラーが出てます。
マイグレーションを忘れてました！
README.mdに書いてあったやつですね。」

【解決】
docker compose exec dify-api flask db upgrade
```

---

### 視聴者への語りかけポイント

```
◆ポイント1
「ここ、初めての人は引っかかりやすいポイントなので、
気をつけてくださいね」

◆ポイント2
「今のコマンド、もう一回見せますね」
[コマンドを再実行]

◆ポイント3
「これ、皆さんの環境でも同じようにできるはずです。
もし違うエラーが出たら、コメント欄に書いてください！」

◆ポイント4
「質問があれば、コメント欄でお待ちしてます！」
```

---

## ⏱️ タイムコード付きチェックリスト

```
□ 00:00 ✋ オープニング（手を振る、笑顔）
□ 01:30 💻 ターミナル表示（フォントサイズ確認）
□ 04:00 🤖 Cursor AI Chat起動（音を入れる）
□ 07:00 🐳 docker compose実行（ログが流れる様子）
□ 10:00 🌐 ブラウザ表示（Dify UI全体を見せる）
□ 13:00 🗄️  psql実行（\dt の結果をゆっくり見せる）
□ 16:00 📁 ファイルアップロード（プログレスバー）
□ 19:00 🎬 まとめ（カメラ目線で話す）
□ 20:00 👋 エンディング（次回予告、手を振る）
```

---

## 🎤 トーク時の注意事項

### 話し方
1. **ゆっくり話す**
   - 普段の70%の速度
   - 専門用語の後は1秒間を置く
   - 「えー」「あのー」は編集でカット

2. **語尾を明確に**
   - 「〜です」「〜ます」ではっきり終わる
   - 語尾を伸ばさない

3. **リアクションを入れる**
   - 「おー」「なるほど」「すごい」
   - 視聴者と同じ目線で驚く

---

### 画面操作
1. **マウスカーソルで指す**
   - 「ここ」と言いながら該当箇所を指す
   - カーソルをゆっくり動かす

2. **スクロールはゆっくり**
   - 視聴者が読める速度
   - 重要部分で3秒停止

3. **コマンド入力はゆっくり**
   - タイプミスを恐れない
   - 視聴者が真似できる速度

---

### エネルギー配分
```
00:00-05:00 ⚡⚡⚡ 高エネルギー（つかみ）
05:00-15:00 ⚡⚡☆ 中エネルギー（解説）
15:00-20:00 ⚡⚡⚡ 高エネルギー（まとめ）
```

---

## 📝 録画後の確認事項

### 技術的確認
- [ ] 音声レベル: -12dB ± 3dB
- [ ] 画面解像度: 1920x1080
- [ ] フレームレート: 30fps以上
- [ ] コーデック: H.264

### 内容確認
- [ ] すべてのコマンドが実行されている
- [ ] エラーシーンが含まれている（教育的）
- [ ] AIの回答がすべて表示されている
- [ ] 次回予告が入っている

---

## 🎥 録画開始の合図

```
深呼吸 × 3回
笑顔を作る
録画ボタンを押す

「3... 2... 1...」

[オープニングへ]
```

---

## 📞 トラブル時の対応

### 録画中に問題が起きたら

**パターン1: 噛んだ・言い間違い**
→ 「すみません、もう一回言います」と言って続ける

**パターン2: コマンドが失敗**
→ 「これは想定外ですね。調査します」とAIに質問

**パターン3: 時間オーバー**
→ 「詳細は次回に持ち越します」でまとめる

---

**頑張ってください！この台本通りに進めれば、素晴らしいコンテンツになります！🎉**

